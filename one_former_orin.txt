backbone.patch_embed.proj.weight------>torch.Size([192, 3, 4, 4])
backbone.patch_embed.proj.bias------>torch.Size([192])
backbone.patch_embed.norm.weight------>torch.Size([192])
backbone.patch_embed.norm.bias------>torch.Size([192])
backbone.layers.0.blocks.0.norm1.weight------>torch.Size([192])
backbone.layers.0.blocks.0.norm1.bias------>torch.Size([192])
backbone.layers.0.blocks.0.attn.relative_position_bias_table------>torch.Size([529, 6])
backbone.layers.0.blocks.0.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.0.blocks.0.attn.qkv.weight------>torch.Size([576, 192])
backbone.layers.0.blocks.0.attn.qkv.bias------>torch.Size([576])
backbone.layers.0.blocks.0.attn.proj.weight------>torch.Size([192, 192])
backbone.layers.0.blocks.0.attn.proj.bias------>torch.Size([192])
backbone.layers.0.blocks.0.norm2.weight------>torch.Size([192])
backbone.layers.0.blocks.0.norm2.bias------>torch.Size([192])
backbone.layers.0.blocks.0.mlp.fc1.weight------>torch.Size([768, 192])
backbone.layers.0.blocks.0.mlp.fc1.bias------>torch.Size([768])
backbone.layers.0.blocks.0.mlp.fc2.weight------>torch.Size([192, 768])
backbone.layers.0.blocks.0.mlp.fc2.bias------>torch.Size([192])
backbone.layers.0.blocks.1.norm1.weight------>torch.Size([192])
backbone.layers.0.blocks.1.norm1.bias------>torch.Size([192])
backbone.layers.0.blocks.1.attn.relative_position_bias_table------>torch.Size([529, 6])
backbone.layers.0.blocks.1.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.0.blocks.1.attn.qkv.weight------>torch.Size([576, 192])
backbone.layers.0.blocks.1.attn.qkv.bias------>torch.Size([576])
backbone.layers.0.blocks.1.attn.proj.weight------>torch.Size([192, 192])
backbone.layers.0.blocks.1.attn.proj.bias------>torch.Size([192])
backbone.layers.0.blocks.1.norm2.weight------>torch.Size([192])
backbone.layers.0.blocks.1.norm2.bias------>torch.Size([192])
backbone.layers.0.blocks.1.mlp.fc1.weight------>torch.Size([768, 192])
backbone.layers.0.blocks.1.mlp.fc1.bias------>torch.Size([768])
backbone.layers.0.blocks.1.mlp.fc2.weight------>torch.Size([192, 768])
backbone.layers.0.blocks.1.mlp.fc2.bias------>torch.Size([192])
backbone.layers.0.downsample.reduction.weight------>torch.Size([384, 768])
backbone.layers.0.downsample.norm.weight------>torch.Size([768])
backbone.layers.0.downsample.norm.bias------>torch.Size([768])
backbone.layers.1.blocks.0.norm1.weight------>torch.Size([384])
backbone.layers.1.blocks.0.norm1.bias------>torch.Size([384])
backbone.layers.1.blocks.0.attn.relative_position_bias_table------>torch.Size([529, 12])
backbone.layers.1.blocks.0.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.1.blocks.0.attn.qkv.weight------>torch.Size([1152, 384])
backbone.layers.1.blocks.0.attn.qkv.bias------>torch.Size([1152])
backbone.layers.1.blocks.0.attn.proj.weight------>torch.Size([384, 384])
backbone.layers.1.blocks.0.attn.proj.bias------>torch.Size([384])
backbone.layers.1.blocks.0.norm2.weight------>torch.Size([384])
backbone.layers.1.blocks.0.norm2.bias------>torch.Size([384])
backbone.layers.1.blocks.0.mlp.fc1.weight------>torch.Size([1536, 384])
backbone.layers.1.blocks.0.mlp.fc1.bias------>torch.Size([1536])
backbone.layers.1.blocks.0.mlp.fc2.weight------>torch.Size([384, 1536])
backbone.layers.1.blocks.0.mlp.fc2.bias------>torch.Size([384])
backbone.layers.1.blocks.1.norm1.weight------>torch.Size([384])
backbone.layers.1.blocks.1.norm1.bias------>torch.Size([384])
backbone.layers.1.blocks.1.attn.relative_position_bias_table------>torch.Size([529, 12])
backbone.layers.1.blocks.1.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.1.blocks.1.attn.qkv.weight------>torch.Size([1152, 384])
backbone.layers.1.blocks.1.attn.qkv.bias------>torch.Size([1152])
backbone.layers.1.blocks.1.attn.proj.weight------>torch.Size([384, 384])
backbone.layers.1.blocks.1.attn.proj.bias------>torch.Size([384])
backbone.layers.1.blocks.1.norm2.weight------>torch.Size([384])
backbone.layers.1.blocks.1.norm2.bias------>torch.Size([384])
backbone.layers.1.blocks.1.mlp.fc1.weight------>torch.Size([1536, 384])
backbone.layers.1.blocks.1.mlp.fc1.bias------>torch.Size([1536])
backbone.layers.1.blocks.1.mlp.fc2.weight------>torch.Size([384, 1536])
backbone.layers.1.blocks.1.mlp.fc2.bias------>torch.Size([384])
backbone.layers.1.downsample.reduction.weight------>torch.Size([768, 1536])
backbone.layers.1.downsample.norm.weight------>torch.Size([1536])
backbone.layers.1.downsample.norm.bias------>torch.Size([1536])
backbone.layers.2.blocks.0.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.0.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.0.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.0.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.0.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.0.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.0.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.0.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.0.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.0.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.0.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.0.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.0.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.0.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.1.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.1.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.1.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.1.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.1.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.1.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.1.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.1.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.1.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.1.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.1.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.1.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.1.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.1.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.2.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.2.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.2.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.2.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.2.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.2.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.2.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.2.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.2.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.2.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.2.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.2.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.2.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.2.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.3.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.3.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.3.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.3.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.3.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.3.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.3.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.3.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.3.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.3.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.3.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.3.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.3.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.3.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.4.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.4.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.4.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.4.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.4.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.4.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.4.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.4.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.4.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.4.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.4.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.4.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.4.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.4.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.5.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.5.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.5.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.5.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.5.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.5.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.5.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.5.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.5.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.5.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.5.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.5.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.5.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.5.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.6.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.6.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.6.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.6.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.6.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.6.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.6.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.6.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.6.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.6.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.6.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.6.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.6.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.6.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.7.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.7.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.7.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.7.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.7.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.7.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.7.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.7.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.7.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.7.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.7.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.7.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.7.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.7.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.8.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.8.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.8.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.8.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.8.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.8.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.8.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.8.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.8.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.8.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.8.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.8.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.8.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.8.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.9.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.9.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.9.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.9.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.9.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.9.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.9.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.9.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.9.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.9.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.9.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.9.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.9.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.9.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.10.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.10.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.10.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.10.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.10.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.10.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.10.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.10.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.10.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.10.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.10.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.10.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.10.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.10.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.11.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.11.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.11.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.11.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.11.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.11.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.11.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.11.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.11.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.11.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.11.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.11.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.11.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.11.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.12.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.12.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.12.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.12.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.12.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.12.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.12.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.12.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.12.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.12.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.12.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.12.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.12.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.12.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.13.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.13.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.13.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.13.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.13.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.13.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.13.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.13.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.13.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.13.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.13.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.13.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.13.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.13.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.14.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.14.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.14.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.14.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.14.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.14.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.14.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.14.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.14.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.14.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.14.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.14.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.14.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.14.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.15.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.15.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.15.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.15.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.15.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.15.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.15.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.15.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.15.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.15.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.15.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.15.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.15.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.15.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.16.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.16.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.16.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.16.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.16.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.16.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.16.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.16.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.16.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.16.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.16.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.16.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.16.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.16.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.blocks.17.norm1.weight------>torch.Size([768])
backbone.layers.2.blocks.17.norm1.bias------>torch.Size([768])
backbone.layers.2.blocks.17.attn.relative_position_bias_table------>torch.Size([529, 24])
backbone.layers.2.blocks.17.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.2.blocks.17.attn.qkv.weight------>torch.Size([2304, 768])
backbone.layers.2.blocks.17.attn.qkv.bias------>torch.Size([2304])
backbone.layers.2.blocks.17.attn.proj.weight------>torch.Size([768, 768])
backbone.layers.2.blocks.17.attn.proj.bias------>torch.Size([768])
backbone.layers.2.blocks.17.norm2.weight------>torch.Size([768])
backbone.layers.2.blocks.17.norm2.bias------>torch.Size([768])
backbone.layers.2.blocks.17.mlp.fc1.weight------>torch.Size([3072, 768])
backbone.layers.2.blocks.17.mlp.fc1.bias------>torch.Size([3072])
backbone.layers.2.blocks.17.mlp.fc2.weight------>torch.Size([768, 3072])
backbone.layers.2.blocks.17.mlp.fc2.bias------>torch.Size([768])
backbone.layers.2.downsample.reduction.weight------>torch.Size([1536, 3072])
backbone.layers.2.downsample.norm.weight------>torch.Size([3072])
backbone.layers.2.downsample.norm.bias------>torch.Size([3072])
backbone.layers.3.blocks.0.norm1.weight------>torch.Size([1536])
backbone.layers.3.blocks.0.norm1.bias------>torch.Size([1536])
backbone.layers.3.blocks.0.attn.relative_position_bias_table------>torch.Size([529, 48])
backbone.layers.3.blocks.0.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.3.blocks.0.attn.qkv.weight------>torch.Size([4608, 1536])
backbone.layers.3.blocks.0.attn.qkv.bias------>torch.Size([4608])
backbone.layers.3.blocks.0.attn.proj.weight------>torch.Size([1536, 1536])
backbone.layers.3.blocks.0.attn.proj.bias------>torch.Size([1536])
backbone.layers.3.blocks.0.norm2.weight------>torch.Size([1536])
backbone.layers.3.blocks.0.norm2.bias------>torch.Size([1536])
backbone.layers.3.blocks.0.mlp.fc1.weight------>torch.Size([6144, 1536])
backbone.layers.3.blocks.0.mlp.fc1.bias------>torch.Size([6144])
backbone.layers.3.blocks.0.mlp.fc2.weight------>torch.Size([1536, 6144])
backbone.layers.3.blocks.0.mlp.fc2.bias------>torch.Size([1536])
backbone.layers.3.blocks.1.norm1.weight------>torch.Size([1536])
backbone.layers.3.blocks.1.norm1.bias------>torch.Size([1536])
backbone.layers.3.blocks.1.attn.relative_position_bias_table------>torch.Size([529, 48])
backbone.layers.3.blocks.1.attn.relative_position_index------>torch.Size([144, 144])
backbone.layers.3.blocks.1.attn.qkv.weight------>torch.Size([4608, 1536])
backbone.layers.3.blocks.1.attn.qkv.bias------>torch.Size([4608])
backbone.layers.3.blocks.1.attn.proj.weight------>torch.Size([1536, 1536])
backbone.layers.3.blocks.1.attn.proj.bias------>torch.Size([1536])
backbone.layers.3.blocks.1.norm2.weight------>torch.Size([1536])
backbone.layers.3.blocks.1.norm2.bias------>torch.Size([1536])
backbone.layers.3.blocks.1.mlp.fc1.weight------>torch.Size([6144, 1536])
backbone.layers.3.blocks.1.mlp.fc1.bias------>torch.Size([6144])
backbone.layers.3.blocks.1.mlp.fc2.weight------>torch.Size([1536, 6144])
backbone.layers.3.blocks.1.mlp.fc2.bias------>torch.Size([1536])
backbone.norm0.weight------>torch.Size([192])
backbone.norm0.bias------>torch.Size([192])
backbone.norm1.weight------>torch.Size([384])
backbone.norm1.bias------>torch.Size([384])
backbone.norm2.weight------>torch.Size([768])
backbone.norm2.bias------>torch.Size([768])
backbone.norm3.weight------>torch.Size([1536])
backbone.norm3.bias------>torch.Size([1536])
sem_seg_head.pixel_decoder.input_proj.0.0.weight------>torch.Size([256, 1536, 1, 1])
sem_seg_head.pixel_decoder.input_proj.0.0.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.input_proj.0.1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.input_proj.0.1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.input_proj.1.0.weight------>torch.Size([256, 768, 1, 1])
sem_seg_head.pixel_decoder.input_proj.1.0.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.input_proj.1.1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.input_proj.1.1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.input_proj.2.0.weight------>torch.Size([256, 384, 1, 1])
sem_seg_head.pixel_decoder.input_proj.2.0.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.input_proj.2.1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.input_proj.2.1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.level_embed------>torch.Size([3, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.bias------>torch.Size([192])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.weight------>torch.Size([96, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.bias------>torch.Size([96])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.weight------>torch.Size([1024, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.bias------>torch.Size([1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.weight------>torch.Size([256, 1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.bias------>torch.Size([192])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.weight------>torch.Size([96, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.bias------>torch.Size([96])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.weight------>torch.Size([1024, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.bias------>torch.Size([1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.weight------>torch.Size([256, 1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.bias------>torch.Size([192])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.weight------>torch.Size([96, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.bias------>torch.Size([96])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.weight------>torch.Size([1024, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.bias------>torch.Size([1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.weight------>torch.Size([256, 1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.bias------>torch.Size([192])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.weight------>torch.Size([96, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.bias------>torch.Size([96])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.weight------>torch.Size([1024, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.bias------>torch.Size([1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.weight------>torch.Size([256, 1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.bias------>torch.Size([192])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.weight------>torch.Size([96, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.bias------>torch.Size([96])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.weight------>torch.Size([1024, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.bias------>torch.Size([1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.weight------>torch.Size([256, 1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.weight------>torch.Size([192, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.bias------>torch.Size([192])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.weight------>torch.Size([96, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.bias------>torch.Size([96])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.weight------>torch.Size([256, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.weight------>torch.Size([1024, 256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.bias------>torch.Size([1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.weight------>torch.Size([256, 1024])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.mask_features.weight------>torch.Size([256, 256, 1, 1])
sem_seg_head.pixel_decoder.mask_features.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.adapter_1.weight------>torch.Size([256, 192, 1, 1])
sem_seg_head.pixel_decoder.adapter_1.norm.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.adapter_1.norm.bias------>torch.Size([256])
sem_seg_head.pixel_decoder.layer_1.weight------>torch.Size([256, 256, 3, 3])
sem_seg_head.pixel_decoder.layer_1.norm.weight------>torch.Size([256])
sem_seg_head.pixel_decoder.layer_1.norm.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.class_transformer.decoder.layers.0.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.class_transformer.decoder.layers.0.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.class_transformer.decoder.layers.0.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.class_transformer.decoder.layers.0.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.norm1.weight------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.norm1.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.norm2.weight------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.norm2.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.norm3.weight------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.0.norm3.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.class_transformer.decoder.layers.1.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.class_transformer.decoder.layers.1.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.class_transformer.decoder.layers.1.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.class_transformer.decoder.layers.1.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.norm1.weight------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.norm1.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.norm2.weight------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.norm2.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.norm3.weight------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.layers.1.norm3.bias------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.norm.weight------>torch.Size([256])
sem_seg_head.predictor.class_transformer.decoder.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.0.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.0.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.1.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.1.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.2.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.2.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.3.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.3.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.4.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.4.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.5.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.5.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.6.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.6.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.7.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.7.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.8.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_self_attention_layers.8.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.0.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.1.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.2.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.3.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.4.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.5.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.6.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.7.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_weight------>torch.Size([768, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_bias------>torch.Size([768])
sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight------>torch.Size([256, 256])
sem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_cross_attention_layers.8.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.0.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.0.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.0.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.0.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.0.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.0.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.1.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.1.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.1.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.1.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.1.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.1.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.2.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.2.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.2.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.2.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.2.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.2.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.3.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.3.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.3.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.3.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.3.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.3.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.4.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.4.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.4.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.4.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.4.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.4.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.5.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.5.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.5.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.5.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.5.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.5.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.6.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.6.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.6.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.6.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.6.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.6.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.7.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.7.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.7.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.7.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.7.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.7.norm.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.8.linear1.weight------>torch.Size([2048, 256])
sem_seg_head.predictor.transformer_ffn_layers.8.linear1.bias------>torch.Size([2048])
sem_seg_head.predictor.transformer_ffn_layers.8.linear2.weight------>torch.Size([256, 2048])
sem_seg_head.predictor.transformer_ffn_layers.8.linear2.bias------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.8.norm.weight------>torch.Size([256])
sem_seg_head.predictor.transformer_ffn_layers.8.norm.bias------>torch.Size([256])
sem_seg_head.predictor.decoder_norm.weight------>torch.Size([256])
sem_seg_head.predictor.decoder_norm.bias------>torch.Size([256])
sem_seg_head.predictor.query_embed.weight------>torch.Size([150, 256])
sem_seg_head.predictor.level_embed.weight------>torch.Size([3, 256])
sem_seg_head.predictor.class_input_proj.weight------>torch.Size([256, 256, 1, 1])
sem_seg_head.predictor.class_input_proj.bias------>torch.Size([256])
sem_seg_head.predictor.class_embed.weight------>torch.Size([134, 256])
sem_seg_head.predictor.class_embed.bias------>torch.Size([134])
sem_seg_head.predictor.mask_embed.layers.0.weight------>torch.Size([256, 256])
sem_seg_head.predictor.mask_embed.layers.0.bias------>torch.Size([256])
sem_seg_head.predictor.mask_embed.layers.1.weight------>torch.Size([256, 256])
sem_seg_head.predictor.mask_embed.layers.1.bias------>torch.Size([256])
sem_seg_head.predictor.mask_embed.layers.2.weight------>torch.Size([256, 256])
sem_seg_head.predictor.mask_embed.layers.2.bias------>torch.Size([256])
task_mlp.layers.0.weight------>torch.Size([256, 77])
task_mlp.layers.0.bias------>torch.Size([256])
task_mlp.layers.1.weight------>torch.Size([256, 256])
task_mlp.layers.1.bias------>torch.Size([256])
criterion.logit_scale------>torch.Size([])
criterion.empty_weight------>torch.Size([134])
